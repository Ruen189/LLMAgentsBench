=== Q1 ===
MODEL OUTPUT:
user
Ты строгий методист. Отвечай строго по контексту. Если ответа нет в контексте — напиши 'Не найдено в контексте'. Для ключевых утверждений приводи цитаты в формате [doc#p=N].

Ты строгий методист и проверяющий бенча.

ДАНО:
Ниже контекст из документа. Каждый фрагмент начинается с ссылки в квадратных скобках вида [CITATION].
Разрешено цитировать ТОЛЬКО эти ссылки, строго копируя их как есть.

ВОПРОС:
Какова цель проекта и на каком продукте он реализуется?

КОНТЕКСТ:
[ОТЧЁТ Diamond.pdf#p=17] (folder=ОТЧЁТ Diamond, page=17)
ПРИЛОЖЕНИЕ А
Техническое Задание (ТЗ) для проекта "RH AI memory and EdAgent"
Общие сведения о проекте
Название проекта: Реляционная память для ИИ-агентов
Описание: Система управления опытом для ИИ-агентских систем на продукте
ПроКомпетенции. Проект включает создание агента для сопровождения проект-
ного обучения в УрФУ и других университетах, разработанного на 4 задачи: раз-
работка памяти на идеях RFT и NARS, совмещая когнитивную науку и приклад-
ные ИИ
компоненты, QLORA адаптеры для "склейки" LLM и память напрямую, модель
поведенческих данных и сам ИИ-агент для ПроКомпетенций.
Структура выполнения проекта по фазам
ФАЗА 1: АНАЛИЗ ИНДУСТРИИ И КОМПЕТЕНЦИЙ
Цель фазы
Определить актуальные компетенции в индустрии и выявить зоны наибольшего
соответствия и пробелов между индустрией и программой обучения.
Автономные действия Агента
Задача 1.1: Анализ открытых данных рынка труда
Собрать данные о вакансиях, отчетах, трендах через публичные API и
•
веб- скрейпинг
Источники: HeadHunter, Superjob, LinkedIn, отраслевые отчеты
•
Парсинг требований к компетенциям из описаний вакансий
•
Формирование базы данных актуальных компетенций по направлениям
•
Задача 1.2: Сопоставление компетенций
Анализ учебной программы ПроКомпетенции
•
Извлечение компетенций из учебных планов и курсов
•
Сравнение с индустриальными требованиями
•
Построение матрицы соответствия компетенций
•

---
[Функциональные_требования_агента.pdf#p=1] (folder=Функциональные_требования_агента, page=1)
Техническое Задание (ТЗ) для проекта "RH AI memory and EdAgent"
Общие сведения о проекте
Название проекта: Реляционная память для ИИ-агентов
Описание: Система управления опытом для ИИ-агентских систем на продукте
ПроКомпетенции. Проект включает создание агента для сопровождения проектного
обучения в УрФУ и других университетах, разработанного на 4 задачи: разработка
памяти на идеях RFT и NARS, совмещая когнитивную науку и прикладные ИИ
компоненты, QLORA адаптеры для "склейки" LLM и память напрямую, модель
поведенческих данных и сам ИИ-агент для ПроКомпетенций.
Структура выполнения проекта по фазам
ФАЗА 1: АНАЛИЗ ИНДУСТРИИ И КОМПЕТЕНЦИЙ
Цель фазы
Определить актуальные компетенции в индустрии и выявить зоны наибольшего
соответствия и пробелов между индустрией и программой обучения.
Автономные действия Агента
Задача 1.1: Анализ открытых данных рынка труда
• Собрать данные о вакансиях, отчетах, трендах через публичные API и веб-
скрейпинг
• Источники: HeadHunter, Superjob, LinkedIn, отраслевые отчеты
• Парсинг требований к компетенциям из описаний вакансий
• Формирование базы данных актуальных компетенций по направлениям
Задача 1.2: Сопоставление компетенций
• Анализ учебной программы ПроКомпетенции
• Извлечение компетенций из учебных планов и курсов
• Сравнение с индустриальными требованиями
• Построение матрицы соответствия компетенций
• Выявление пробелов и зон избыточности
Задача 1.3: Формирование аналитического отчета
• Генерация статистики по востребованности компетенций
• Визуализация пробелов и зон соответствия

---
[ОТЧЁТ Diamond.pdf#p=3] (folder=ОТЧЁТ Diamond, page=3)
Цель проекта — разработать систему управления опытом (реляционной
памяти) для ИИ‑агентских систем на продукте «ПроКомпетенции»[1], чтобы
повысить качество сопровождения проектного обучения за счёт
автоматизированного анализа компетенций, выявления пробелов и генерации
рекомендаций.
В рамках семестра были поставлены команда выполняла следующие
задачи: подготовка основы для ИИ‑агента сопровождения проектного обучения
на платформе «ПроКомпетенции»: выбрать технологический стек и модель
агента, обеспечить адаптацию LLM[2] под домен проекта с помощью
QLoRA[3], а также реализовать интерфейс для удобного взаимодействия
пользователей с агентом.
Актуальность проекта обусловлена тем, что образовательные программы
проектного обучения быстро сталкиваются с разрывом между тем, чему
обучают, и тем, что требуется рынку труда; это приводит к снижению
практической ценности обучения и повышает нагрузку на организаторов,
которым нужно регулярно обновлять содержание и контролировать
соответствие компетенций.
Область применения — цифровая платформа сопровождения проектного
обучения «ПроКомпетенции». Потенциально может интегрироваться на любых
проектных платформах, так как агент анализирует проекты не зависимо от
платформы.
Ожидаемые результаты и планируемые достижения (по итогам семестра):
1) Рабочий прототип ИИ‑агента (LLM‑ядро + сценарии) для
сопровождения проектного обучения на платформе
«ПроКомпетенции», ориентированный на задачи анализа компетенций
и подготовки текстовых выводов.
2) Работа с данными: сбор и подготовка данных о вакансиях, извлечение
компетенций из вакансий и учебных проектов, сопоставление спроса и
предложения по индустриям, формирование матриц соответствия.
3) Набор артефактов аналитики, пригодных для принятия решений:
статистика востребованности компетенций, визуализации, а также
текстовые рекомендации.

---
[ОТЧЁТ Diamond.pdf#p=25] (folder=ОТЧЁТ Diamond, page=25)
ФАЗА 4: OUTREACH И КВАЛИФИКАЦИЯ
Цель фазы
Установить контакт с компаниями, получить обратную связь и квалифицировать
заинтересованных партнеров.
Автономные действия Агента
Задача 4.1: Отправка утвержденных писем (Outreach)
Автоматическая рассылка через email/LinkedIn
•
Отслеживание статусов доставки
•
Фиксация времени отправки и получения
•
Задача 4.2: Мониторинг и квалификация ответов
Отслеживание входящих ответов (заинтересован, отказ, требует уточнения)
•
Категоризация ответов по типам
•
Первичная квалификация: уровень интереса, готовность к встрече
•
Автоматическая обработка простых отказов и FAQ-вопросов
•
Задача 4.3: Автоматические фоллоу-апы
Отправка напоминаний неответившим компаниям (через 7-14 дней)
•
Генерация дополнительных материалов по запросу
•
Планирование следующих касаний
•
Критическая точка эскалации № 4
Условие активации: Получен положительный ответ с запросом на встречу
или любым другим способом уточнения деталей проекта.
Действие Человека:
Вступает в личный диалог с представителем компании
•
Проводит встречу (онлайн/офлайн)
•
Обсуждает детали проекта
•
Заключает неформальное или формальное соглашение
•
Фиксирует договоренности в системе
•

---
[Функциональные_требования_агента.pdf#p=5] (folder=Функциональные_требования_агента, page=5)
ФАЗА 4: OUTREACH И КВАЛИФИКАЦИЯ
Цель фазы
Установить контакт с компаниями, получить обратную связь и квалифицировать
заинтересованных партнеров.
Автономные действия Агента
Задача 4.1: Отправка утвержденных писем (Outreach)
• Автоматическая рассылка через email/LinkedIn
• Отслеживание статусов доставки
• Фиксация времени отправки и получения
Задача 4.2: Мониторинг и квалификация ответов
• Отслеживание входящих ответов (заинтересован, отказ, требует уточнения)
• Категоризация ответов по типам
• Первичная квалификация: уровень интереса, готовность к встрече
• Автоматическая обработка простых отказов и FAQ-вопросов
Задача 4.3: Автоматические фоллоу-апы
• Отправка напоминаний неответившим компаниям (через 7-14 дней)
• Генерация дополнительных материалов по запросу
• Планирование следующих касаний
Критическая точка эскалации № 4
Условие активации: Получен положительный ответ с запросом на встречу или
любым другим способом уточнения деталей проекта.
Действие Человека:
• Вступает в личный диалог с представителем компании
• Проводит встречу (онлайн/офлайн)
• Обсуждает детали проекта
• Заключает неформальное или формальное соглашение
• Фиксирует договоренности в системе
Результат Фазы 4
Артефакт: Подтвержденные Проектные Задачи и завершенное Партнерское
Соглашение

---
[ОТЧЁТ Diamond.pdf#p=11] (folder=ОТЧЁТ Diamond, page=11)
происходит аналогичным образом в разных вкладках интерфейса.
Рисунок 3 - Работа с интерфейсом, на примере матриц и статистики
Интерфейс не подразумевает обучение QLoRA-адаптеров.
Обучение QLoRA-адаптеров происходит в отдельном Jupyter Notebook в
репозитории проекта.

ПРАВИЛА:
- Отвечай строго по контексту. Никаких знаний "из головы".
- Если прямого ответа нет в контексте — напиши ровно: Не найдено в контексте.
- Запрещено придумывать цитаты/страницы/идентификаторы.
- Любое ключевое утверждение в ответе должно быть подтверждено 1–3 цитатами из контекста.

ФОРМАТ ОТВЕТА (строго, 2 строки):
Ответ: <1–3 коротких предложения или "Не найдено в контексте.">
Цитаты: <1–3 цитаты вида [....] из контекста, либо "—" если не найдено>

assistant
<think>
Хорошо, давайте разберемся с этим вопросом. Нужно определить цель проекта и на каком продукте он реализуется. 

Сначала посмотрю на контекст. В документе [ОТЧЁТ Diamond.pdf#p=3] говорится, что цель проекта — разработать систему управления опытом (реляционную память) для ИИ-агентских систем на продукте «ПроКомпетенции». Также упоминается, что область применения — цифровая платформа сопровождения проектного обучения «ПроКомпетенции». 

В других частях документов, например, в [Функциональные_требования_агента.pdf#p=1], повторяется, что проект включает создание агента для сопровождения проектного обучения в УрФУ и других университетах на продукте ПроКомпетенции. 

Таким образом, цель проекта — создание системы реляционной памяти для ИИ-агентов, которая будет использоваться в рамках продукта «ПроКомпетенции». Нужно убедиться, что в цитатах точно указаны эти моменты. Проверю, нет ли других упоминаний. В [ОТЧЁТ Diamond.pdf#p=17] тоже говорится о продукте ПроКомпетенции. 

Все ключевые моменты подтверждены цитатами из указанных источников. Теперь оформлю ответ по правилам: короткий ответ и цитаты.
</think>

Ответ: Цель проекта — разработка системы реляционной памяти для ИИ-агентов на продукте «ПроКомпетенции» для повышения качества сопровождения проектного обучения.  
Цитаты: [ОТЧЁТ Diamond.pdf#p=3], [Функциональные_требования_агента.pdf#p=1], [ОТЧЁТ Diamond.pdf#p=17]

=== Q2 ===
MODEL OUTPUT:
user
Ты строгий методист. Отвечай строго по контексту. Если ответа нет в контексте — напиши 'Не найдено в контексте'. Для ключевых утверждений приводи цитаты в формате [doc#p=N].

Ты строгий методист и проверяющий бенча.

ДАНО:
Ниже контекст из документа. Каждый фрагмент начинается с ссылки в квадратных скобках вида [CITATION].
Разрешено цитировать ТОЛЬКО эти ссылки, строго копируя их как есть.

ВОПРОС:
Перечисли ожидаемые результаты/достижения по итогам семестра (пункты 1–3).

КОНТЕКСТ:
[ОТЧЁТ Diamond.pdf#p=3] (folder=ОТЧЁТ Diamond, page=3)
Цель проекта — разработать систему управления опытом (реляционной
памяти) для ИИ‑агентских систем на продукте «ПроКомпетенции»[1], чтобы
повысить качество сопровождения проектного обучения за счёт
автоматизированного анализа компетенций, выявления пробелов и генерации
рекомендаций.
В рамках семестра были поставлены команда выполняла следующие
задачи: подготовка основы для ИИ‑агента сопровождения проектного обучения
на платформе «ПроКомпетенции»: выбрать технологический стек и модель
агента, обеспечить адаптацию LLM[2] под домен проекта с помощью
QLoRA[3], а также реализовать интерфейс для удобного взаимодействия
пользователей с агентом.
Актуальность проекта обусловлена тем, что образовательные программы
проектного обучения быстро сталкиваются с разрывом между тем, чему
обучают, и тем, что требуется рынку труда; это приводит к снижению
практической ценности обучения и повышает нагрузку на организаторов,
которым нужно регулярно обновлять содержание и контролировать
соответствие компетенций.
Область применения — цифровая платформа сопровождения проектного
обучения «ПроКомпетенции». Потенциально может интегрироваться на любых
проектных платформах, так как агент анализирует проекты не зависимо от
платформы.
Ожидаемые результаты и планируемые достижения (по итогам семестра):
1) Рабочий прототип ИИ‑агента (LLM‑ядро + сценарии) для
сопровождения проектного обучения на платформе
«ПроКомпетенции», ориентированный на задачи анализа компетенций
и подготовки текстовых выводов.
2) Работа с данными: сбор и подготовка данных о вакансиях, извлечение
компетенций из вакансий и учебных проектов, сопоставление спроса и
предложения по индустриям, формирование матриц соответствия.
3) Набор артефактов аналитики, пригодных для принятия решений:
статистика востребованности компетенций, визуализации, а также
текстовые рекомендации.

---
[ОТЧЁТ Diamond.pdf#p=15] (folder=ОТЧЁТ Diamond, page=15)
ЗАКЛЮЧЕНИЕ
Соответствие требованиям заказчика: по итогам семестра создан
работоспособный прототип, который автоматизирует ключевой сценарий Фазы
1 — извлечение и сопоставление компетенций между рынком труда и учебными
проектами, а также формирует аналитические артефакты (статистика,
визуализации, рекомендации). Это означает, что продукт уже поддерживает
принятие решений по корректировке программы и выбору фокуса анализа, а не
просто “выполняет отдельные задачи”. На данный момент проект не готов к
интеграции в “ПроКомпетенции”, так как интерфейс не подходит для
автономной агентной работы. Тем не менее, это соответсвует требованиям
заказчика, так как проект не рассчитан на один семестр.
Оценка качества по результатам тестирования: качество продукта
определяется двумя компонентами — корректностью данных и стабильностью
вывода LLM. Выявленные дефекты (ошибки извлечения компетенций,
нестабильный формат, нерелевантные элементы) имеют заметное влияние на
точность аналитики, поэтому ручная валидация и постобработка остаются
обязательными. Иногда встречаются явные галлюцинации из-за жесткого
квантования, что говорит о том, что требуется дообучение адаптеров.
Подключение QLoRA‑адаптера и уточнение промптов улучшают
повторяемость результатов, но полностью не устраняют необходимость
контроля качества на репрезентативных выборках.
Предложения по улучшению и развитию:
1) Ввести автоматическое тестирование;
2) Интегрировать сбор проектов в проект, а не отдельно от проекта в виде
расширения;
3) Использовать динамическое дообучение QLoRA;
4) Интеграция в ПроКомпетенции для тестирования на реальных
пользователях.

---
[ОТЧЁТ Diamond.pdf#p=31] (folder=ОТЧЁТ Diamond, page=31)
FR-3.3: Система должна поддерживать разные стили коммуникации
(формальный/неформальный)
FR-3.4: Система должна генерировать презентационные материалы и FAQ
FR-3.5: Система должна предоставлять интерфейс для утверждения тек-
стов коммуникаций человеком
FR-3.6: Система должна разрабатывать план касаний (первичное письмо + фол-
лоу- апы)
4. Модуль Outreach и квалификации
FR-4.1: Система должна автоматически отправлять утвержденные письма через
email и LinkedIn API
FR-4.2: Система должна отслеживать статусы доставки и прочтения писем
FR-4.3: Система должна мониторить входящие ответы и категоризировать их
(интерес, отказ, вопросы)
FR-4.4: Система должна автоматически обрабатывать простые отказы и типовые
вопросы
FR-4.5: Система должна отправлять автоматические фоллоу-апы по расписанию
FR-4.6: Система должна эскалировать положительные ответы человеку для лич-
ного контакта
FR-4.7: Система должна фиксировать результаты переговоров и соглашения
5. Модуль генерации проектов и ТЗ
FR-5.1: Система должна генерировать технические задания на основе деталей со-
глашения с партнером
FR-5.2: Система должна размечать ТЗ по необходимым модулям и компетенциям
программы
FR-5.3: Система должна разбивать проекты по ролям с требованиями к навыкам
FR-5.4: Система должна интегрировать проекты в каталог системы ПроКомпетен-
ции
FR-5.5: Система должна создавать связи проект-компетенция-партнер
6. Модуль памяти и адаптации агента
FR-6.1: Система должна хранить историю всех взаимодействий с компаниями и
результаты

---
[Функциональные_требования_агента.pdf#p=8] (folder=Функциональные_требования_агента, page=8)
FR-3.3: Система должна поддерживать разные стили коммуникации
(формальный/неформальный)
FR-3.4: Система должна генерировать презентационные материалы и FAQ
FR-3.5: Система должна предоставлять интерфейс для утверждения текстов
коммуникаций человеком
FR-3.6: Система должна разрабатывать план касаний (первичное письмо + фоллоу-
апы)
4. Модуль Outreach и квалификации
FR-4.1: Система должна автоматически отправлять утвержденные письма через email
и LinkedIn API
FR-4.2: Система должна отслеживать статусы доставки и прочтения писем
FR-4.3: Система должна мониторить входящие ответы и категоризировать их
(интерес, отказ, вопросы)
FR-4.4: Система должна автоматически обрабатывать простые отказы и типовые
вопросы
FR-4.5: Система должна отправлять автоматические фоллоу-апы по расписанию
FR-4.6: Система должна эскалировать положительные ответы человеку для личного
контакта
FR-4.7: Система должна фиксировать результаты переговоров и соглашения
5. Модуль генерации проектов и ТЗ
FR-5.1: Система должна генерировать технические задания на основе деталей
соглашения с партнером
FR-5.2: Система должна размечать ТЗ по необходимым модулям и компетенциям
программы
FR-5.3: Система должна разбивать проекты по ролям с требованиями к навыкам
FR-5.4: Система должна интегрировать проекты в каталог системы ПроКомпетенции
FR-5.5: Система должна создавать связи проект-компетенция-партнер
6. Модуль памяти и адаптации агента
FR-6.1: Система должна хранить историю всех взаимодействий с компаниями и
результаты
FR-6.2: Система должна обучаться на основе успешных и неуспешных коммуникаций
FR-6.3: Система должна использовать QLORA адаптеры для улучшения генерации
текстов

---
[ОТЧЁТ Diamond.pdf#p=8] (folder=ОТЧЁТ Diamond, page=8)
Универсальные LLM‑чатботы способны отвечать на запросы и извлекать
навыки, но без доменной адаптации и контроля качества дают нестабильные
результаты и плохо масштабируются на большие массивы вакансий/проектов.
Фактически прямых цифровых аналогов, которые анализируют проекты
из проектных платформ нет и сверяют с вакансиями по компетенциям нет.

---
[ОТЧЁТ Diamond.pdf#p=18] (folder=ОТЧЁТ Diamond, page=18)
Выявление пробелов и зон избыточности
•
Задача 1.3: Формирование аналитического отчета
Генерация статистики по востребованности компетенций
•
Визуализация пробелов и зон соответствия
•
Формирование рекомендаций по корректировке программы
•

ПРАВИЛА:
- Отвечай строго по контексту. Никаких знаний "из головы".
- Если прямого ответа нет в контексте — напиши ровно: Не найдено в контексте.
- Запрещено придумывать цитаты/страницы/идентификаторы.
- Любое ключевое утверждение в ответе должно быть подтверждено 1–3 цитатами из контекста.

ФОРМАТ ОТВЕТА (строго, 2 строки):
Ответ: <1–3 коротких предложения или "Не найдено в контексте.">
Цитаты: <1–3 цитаты вида [....] из контекста, либо "—" если не найдено>

assistant
<think>
Хорошо, давайте разберемся с этим вопросом. Нужно перечислить ожидаемые результаты/достижения по итогам семестра, пункты 1–3. 

Сначала я должен внимательно изучить предоставленный контекст. Вижу, что в первом документе [ОТЧЁТ Diamond.pdf#p=3] говорится о целях проекта и задачах, которые выполняла команда. В разделе "Ожидаемые результаты и планируемые достижения (по итогам семестра)" указаны три пункта:

1) Рабочий прототип ИИ-агента (LLM-ядро + сценарии) для сопровождения проектного обучения на платформе «ПроКомпетенции», ориентированный на задачи анализа компетенций и подготовки текстовых выводов.

2) Работа с данными: сбор и подготовка данных о вакансиях, извлечение компетенций из вакансий и учебных проектов, сопоставление спроса и предложения по индустриям, формирование матриц соответствия.

3) Набор артефактов аналитики, пригодных для принятия решений: статистика востребованности компетенций, визуализации, а также текстовые рекомендации.

Эти три пункта точно соответствуют требованию вопроса. Теперь нужно проверить, есть ли они в контексте. Да, в первом документе, страница 3, есть прямая ссылка на эти пункты. Также в заключении [ОТЧЁТ Diamond.pdf#p=15] упоминается, что был создан прототип, который автоматизирует извлечение и сопоставление компетенций, а также формирует аналитические артефакты. Это подтверждает первый и третий пункты. Второй пункт о работе с данными тоже есть в первом документе. 

Нужно убедиться, что других источников не нужно привлекать. Например, в других частях контекста

=== Q3 ===
MODEL OUTPUT:
user
Ты строгий методист. Отвечай строго по контексту. Если ответа нет в контексте — напиши 'Не найдено в контексте'. Для ключевых утверждений приводи цитаты в формате [doc#p=N].

Ты строгий методист и проверяющий бенча.

ДАНО:
Ниже контекст из документа. Каждый фрагмент начинается с ссылки в квадратных скобках вида [CITATION].
Разрешено цитировать ТОЛЬКО эти ссылки, строго копируя их как есть.

ВОПРОС:
Почему в архитектуре был реализован парсер как расширение для браузера и какая причина указана?

КОНТЕКСТ:
[ОТЧЁТ Diamond.pdf#p=9] (folder=ОТЧЁТ Diamond, page=9)
2 Архитектура программного продукта.
Так как у «ПроКомпетенции» нет API, был реализован парсер[6] в виде
расширения для браузера. Оно собирает информацию о всех проектах, которые
есть на платформе. У каждого проекта есть свой собственный ID, список
которых можно увидеть в коде страницы «ПроКомпетенции». Так как разным
пользователям видны разные проекты, ID можно указывать вручную.
Подразумевается, что парсер может использоваться не более, чем раз в семестр,
так как проекты обновляются каждый семестр, поэтому парсер был сделан
максимально простым.
Рисунок 1 - Сбор данных проектов при помощи парсера
Данные с парсера сохраняются в виде JSON файла для удобной работы с
ними.
Далее весь проект реализован неразрывно одним репозиторием.
У hh.ru и SuperJob есть свои API, поэтому сборщики вакансий
реализованы прямо в проекте. Поиск вакансий происходит по ключевым
словам.

---
[ОТЧЁТ Diamond.pdf#p=10] (folder=ОТЧЁТ Diamond, page=10)
Рисунок 2 - Сбор данных вакансий в интерфейсе
LLM‑обработка. В качестве LLM используется модель hugging-
quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4[7], так как эта она поддерживает
4-битную квантизацию, что сильно экономит видеопамять и, как следствие,
ускоряет инференс. В качестве движка для быстрого инференса используется
vLLM[8]. Фреймворк vllm был выбран для удобного масштабирование под
разные видеокарты, так как у разработчиков и у заказчика условия сильно
отличаются, а также ускорения инференса. Адаптеры QLoRA при инференсе
используется по желанию.
Рисунок 3 - Работа с интерфейсом, на примере анализа вакансий
Интерфейс работает в браузере и позволяет настроить API-ключи, сбор
данных, анализ вакансий/проектов, использование адаптеров, а также
управлять матрицами и рекомендациями. Анализ вакансий и проектов

---
[ОТЧЁТ Diamond.pdf#p=13] (folder=ОТЧЁТ Diamond, page=13)
3 Методология разработки, промежуточное тестирование и
выявленные ошибки
Методология: итеративная разработка “данные → извлечение →
проверка → улучшение”, потому что качество извлечения компетенций сильно
зависит от промпта, параметров инференса и качества исходных текстов.
Промежуточное тестирование проводилось на реальных вакансиях и
проектах: оценивалась корректность извлечённых компетенций и устойчивость
к “грязным” данным.
По результатам тестирования выявлялись типовые ошибки (пустые
ответы, дубли, нерелевантные компетенции, нестабильный формат), после чего
внедрялись меры: постобработка, уточнение промптов, ручная корректировка в
спорных случаях, эксперименты с параметрами генерации и подключение
QLoRA‑адаптера. Чаще всего возникали ошибки из-за “грязных данных” и
слишком больших промптов, поэтому внедрялись фильтры данных, а также
ограничивался промпт.
Отдельный класс проблем был связан с производительностью и
ограничениями вычислительных ресурсов (VRAM/батчинг/контекст), поэтому
вводились ограничения и настройки режима инференса для стабильной работы
пайплайна. Изначально инференс был построен на обычной не квантованной
Llama-3.1-8B на фреймворке Transformers[9]. Проблемы были очевидны:
огромное потребление памяти, крайне медленный инференс (до получаса),
низкое качества ответа, а также нужно было вручную выбирать размер батчей.
Для ускорения был использован фреймворк vllm, который автоматически
выбирает размер батчей; для уменьшения потребления памяти использовали
квантованную модель, а для повышения качества ответа выбирали модель типа
“Instruct”, то есть заточенные под четкие инструкции.

---
[Diamond кт1.pdf#p=13] (folder=Diamond кт1, page=13)
Llama 3.1 8B
● Небольшая модель из HuggingFace,
для доступа к которой нужен hf
токен
● Модель небольшая, её будем
использовать и дообучать
● Квантизация модели уменьшает её
размер в памяти
● Обработка нескольких инструкций
одновременно ускоряет процесс
многократно
В качестве механизма внимания используется обычный sdpa, но в будущем будет использоваться
другой, скорее всего FlashAttention2, так как последовательность инструкций может вырасти

---
[ОТЧЁТ Diamond.pdf#p=14] (folder=ОТЧЁТ Diamond, page=14)
4 Планирование и распределение задач
Планирование велось по техническим требованиям. Задачи
распределялись по мере возможностей участников. Разработчик с наилучшим
компьютером занимался обучением QLoRA и выбором моделей. Разработчик с
более слабый компьютером занимался реализацией интерфейса, а остальные
участники занимались аналитикой и разработкой прототипа интерфейса.
Такое распределение было фактически единственно возможным
эффективным вариантом, так как разработчика два и лишь один из них
физически мог позволить себе тестировать модели и обучать QLoRA адаптеры.
Общую информацию по проекту обсуждали в группе, а конкретно по
реализации разработчики обсуждали напрямую друг с другом, так как в
команде всего четыре человека, двое из которых разработчики.
Версионирование проекта происходило в GitHub.

---
[ОТЧЁТ Diamond.pdf#p=15] (folder=ОТЧЁТ Diamond, page=15)
ЗАКЛЮЧЕНИЕ
Соответствие требованиям заказчика: по итогам семестра создан
работоспособный прототип, который автоматизирует ключевой сценарий Фазы
1 — извлечение и сопоставление компетенций между рынком труда и учебными
проектами, а также формирует аналитические артефакты (статистика,
визуализации, рекомендации). Это означает, что продукт уже поддерживает
принятие решений по корректировке программы и выбору фокуса анализа, а не
просто “выполняет отдельные задачи”. На данный момент проект не готов к
интеграции в “ПроКомпетенции”, так как интерфейс не подходит для
автономной агентной работы. Тем не менее, это соответсвует требованиям
заказчика, так как проект не рассчитан на один семестр.
Оценка качества по результатам тестирования: качество продукта
определяется двумя компонентами — корректностью данных и стабильностью
вывода LLM. Выявленные дефекты (ошибки извлечения компетенций,
нестабильный формат, нерелевантные элементы) имеют заметное влияние на
точность аналитики, поэтому ручная валидация и постобработка остаются
обязательными. Иногда встречаются явные галлюцинации из-за жесткого
квантования, что говорит о том, что требуется дообучение адаптеров.
Подключение QLoRA‑адаптера и уточнение промптов улучшают
повторяемость результатов, но полностью не устраняют необходимость
контроля качества на репрезентативных выборках.
Предложения по улучшению и развитию:
1) Ввести автоматическое тестирование;
2) Интегрировать сбор проектов в проект, а не отдельно от проекта в виде
расширения;
3) Использовать динамическое дообучение QLoRA;
4) Интеграция в ПроКомпетенции для тестирования на реальных
пользователях.

ПРАВИЛА:
- Отвечай строго по контексту. Никаких знаний "из головы".
- Если прямого ответа нет в контексте — напиши ровно: Не найдено в контексте.
- Запрещено придумывать цитаты/страницы/идентификаторы.
- Любое ключевое утверждение в ответе должно быть подтверждено 1–3 цитатами из контекста.

ФОРМАТ ОТВЕТА (строго, 2 строки):
Ответ: <1–3 коротких предложения или "Не найдено в контексте.">
Цитаты: <1–3 цитаты вида [....] из контекста, либо "—" если не найдено>

assistant
<think>
Хорошо, давайте разберемся с этим вопросом. Пользователь спрашивает, почему в архитектуре был реализован парсер как расширение для браузера и какая причина указана. 

Первым делом нужно найти в контексте информацию о том, почему парсер был сделан в виде расширения браузера. Вспомним, что контекст содержит несколько документов. Посмотрю на первый документ, где говорится о архитектуре. В [ОТЧЁТ Diamond.pdf#p=9] упоминается, что у "ПроКомпетенции" нет API, поэтому был реализован парсер как расширение браузера. Это ключевая часть ответа. Также там говорится, что парсер собирает информацию о проектах, и разным пользователям видны разные проекты, поэтому ID указывают вручную. Еще важно, что парсер используется не чаще одного раза в семестр, так как проекты обновляются каждый семестр, и он сделан максимально простым.

Нужно проверить, есть ли другие упоминания о причинах. В других разделах, например, о LLM или распределении задач, не говорится о причине использования расширения браузера. Значит, основная причина — отсутствие API у платформы и необходимость сбора данных через парсер, который реализован как расширение. Также упоминается, что парсер простой, так как обновляется раз в семестр. 

Теперь нужно сформулировать ответ, используя цитаты. Важно не добавлять лишнего. Цитата из [ОТЧЁТ Diamond.pdf#p=9] будет ключевой. Возможно, еще упоминание о том, что парсер используется не чаще раза в семестр, но это больше о частоте использования, чем о причине реализации. 

Итак, ответ должен содержать, что парсер был реализован как расширение браузера из-за отсутствия API у платформы и необходимости сбора данных. Цитата будет из указанного документа.
</think>

Ответ:

=== Q4 ===
MODEL OUTPUT:
user
Ты строгий методист. Отвечай строго по контексту. Если ответа нет в контексте — напиши 'Не найдено в контексте'. Для ключевых утверждений приводи цитаты в формате [doc#p=N].

Ты строгий методист и проверяющий бенча.

ДАНО:
Ниже контекст из документа. Каждый фрагмент начинается с ссылки в квадратных скобках вида [CITATION].
Разрешено цитировать ТОЛЬКО эти ссылки, строго копируя их как есть.

ВОПРОС:
Какая LLM модель указана как используемая в проекте, и почему выбрана 4-битная квантизация (AWQ INT4)?

КОНТЕКСТ:
[ОТЧЁТ Diamond.pdf#p=10] (folder=ОТЧЁТ Diamond, page=10)
Рисунок 2 - Сбор данных вакансий в интерфейсе
LLM‑обработка. В качестве LLM используется модель hugging-
quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4[7], так как эта она поддерживает
4-битную квантизацию, что сильно экономит видеопамять и, как следствие,
ускоряет инференс. В качестве движка для быстрого инференса используется
vLLM[8]. Фреймворк vllm был выбран для удобного масштабирование под
разные видеокарты, так как у разработчиков и у заказчика условия сильно
отличаются, а также ускорения инференса. Адаптеры QLoRA при инференсе
используется по желанию.
Рисунок 3 - Работа с интерфейсом, на примере анализа вакансий
Интерфейс работает в браузере и позволяет настроить API-ключи, сбор
данных, анализ вакансий/проектов, использование адаптеров, а также
управлять матрицами и рекомендациями. Анализ вакансий и проектов

---
[Diamond кт1.pdf#p=13] (folder=Diamond кт1, page=13)
Llama 3.1 8B
● Небольшая модель из HuggingFace,
для доступа к которой нужен hf
токен
● Модель небольшая, её будем
использовать и дообучать
● Квантизация модели уменьшает её
размер в памяти
● Обработка нескольких инструкций
одновременно ускоряет процесс
многократно
В качестве механизма внимания используется обычный sdpa, но в будущем будет использоваться
другой, скорее всего FlashAttention2, так как последовательность инструкций может вырасти

---
[ОТЧЁТ Diamond.pdf#p=16] (folder=ОТЧЁТ Diamond, page=16)
СПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ
1. ПроКомпетенции https://xn--e1aajagmjdbheh6azd.xn--p1ai/
2. Большая языковая модель
https://ru.wikipedia.org/wiki/%D0%91%D0%BE%D0%BB%D1%8C%D1%88%D
0%B0%D1%8F_%D1%8F%D0%B7%D1%8B%D0%BA%D0%BE%D0%B2%D0
%B0%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C
3. QLoRA: Efficient Finetuning of Quantized LLMs
https://arxiv.org/abs/2305.14314
4. Hh.ru https://hh.ru/
5. SuperJob https://www.superjob.ru/
6. Парсер ПроКомпетенции https://github.com/Ruen189/ProCompetences-Parser
7. hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4 https://hugging-
face.co/hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4
8. vllm https://github.com/vllm-project/vllm
9. Transformers https://huggingface.co/docs/transformers/index

---
[ОТЧЁТ Diamond.pdf#p=9] (folder=ОТЧЁТ Diamond, page=9)
2 Архитектура программного продукта.
Так как у «ПроКомпетенции» нет API, был реализован парсер[6] в виде
расширения для браузера. Оно собирает информацию о всех проектах, которые
есть на платформе. У каждого проекта есть свой собственный ID, список
которых можно увидеть в коде страницы «ПроКомпетенции». Так как разным
пользователям видны разные проекты, ID можно указывать вручную.
Подразумевается, что парсер может использоваться не более, чем раз в семестр,
так как проекты обновляются каждый семестр, поэтому парсер был сделан
максимально простым.
Рисунок 1 - Сбор данных проектов при помощи парсера
Данные с парсера сохраняются в виде JSON файла для удобной работы с
ними.
Далее весь проект реализован неразрывно одним репозиторием.
У hh.ru и SuperJob есть свои API, поэтому сборщики вакансий
реализованы прямо в проекте. Поиск вакансий происходит по ключевым
словам.

---
[ОТЧЁТ Diamond.pdf#p=17] (folder=ОТЧЁТ Diamond, page=17)
ПРИЛОЖЕНИЕ А
Техническое Задание (ТЗ) для проекта "RH AI memory and EdAgent"
Общие сведения о проекте
Название проекта: Реляционная память для ИИ-агентов
Описание: Система управления опытом для ИИ-агентских систем на продукте
ПроКомпетенции. Проект включает создание агента для сопровождения проект-
ного обучения в УрФУ и других университетах, разработанного на 4 задачи: раз-
работка памяти на идеях RFT и NARS, совмещая когнитивную науку и приклад-
ные ИИ
компоненты, QLORA адаптеры для "склейки" LLM и память напрямую, модель
поведенческих данных и сам ИИ-агент для ПроКомпетенций.
Структура выполнения проекта по фазам
ФАЗА 1: АНАЛИЗ ИНДУСТРИИ И КОМПЕТЕНЦИЙ
Цель фазы
Определить актуальные компетенции в индустрии и выявить зоны наибольшего
соответствия и пробелов между индустрией и программой обучения.
Автономные действия Агента
Задача 1.1: Анализ открытых данных рынка труда
Собрать данные о вакансиях, отчетах, трендах через публичные API и
•
веб- скрейпинг
Источники: HeadHunter, Superjob, LinkedIn, отраслевые отчеты
•
Парсинг требований к компетенциям из описаний вакансий
•
Формирование базы данных актуальных компетенций по направлениям
•
Задача 1.2: Сопоставление компетенций
Анализ учебной программы ПроКомпетенции
•
Извлечение компетенций из учебных планов и курсов
•
Сравнение с индустриальными требованиями
•
Построение матрицы соответствия компетенций
•

---
[Функциональные_требования_агента.pdf#p=1] (folder=Функциональные_требования_агента, page=1)
Техническое Задание (ТЗ) для проекта "RH AI memory and EdAgent"
Общие сведения о проекте
Название проекта: Реляционная память для ИИ-агентов
Описание: Система управления опытом для ИИ-агентских систем на продукте
ПроКомпетенции. Проект включает создание агента для сопровождения проектного
обучения в УрФУ и других университетах, разработанного на 4 задачи: разработка
памяти на идеях RFT и NARS, совмещая когнитивную науку и прикладные ИИ
компоненты, QLORA адаптеры для "склейки" LLM и память напрямую, модель
поведенческих данных и сам ИИ-агент для ПроКомпетенций.
Структура выполнения проекта по фазам
ФАЗА 1: АНАЛИЗ ИНДУСТРИИ И КОМПЕТЕНЦИЙ
Цель фазы
Определить актуальные компетенции в индустрии и выявить зоны наибольшего
соответствия и пробелов между индустрией и программой обучения.
Автономные действия Агента
Задача 1.1: Анализ открытых данных рынка труда
• Собрать данные о вакансиях, отчетах, трендах через публичные API и веб-
скрейпинг
• Источники: HeadHunter, Superjob, LinkedIn, отраслевые отчеты
• Парсинг требований к компетенциям из описаний вакансий
• Формирование базы данных актуальных компетенций по направлениям
Задача 1.2: Сопоставление компетенций
• Анализ учебной программы ПроКомпетенции
• Извлечение компетенций из учебных планов и курсов
• Сравнение с индустриальными требованиями
• Построение матрицы соответствия компетенций
• Выявление пробелов и зон избыточности
Задача 1.3: Формирование аналитического отчета
• Генерация статистики по востребованности компетенций
• Визуализация пробелов и зон соответствия

ПРАВИЛА:
- Отвечай строго по контексту. Никаких знаний "из головы".
- Если прямого ответа нет в контексте — напиши ровно: Не найдено в контексте.
- Запрещено придумывать цитаты/страницы/идентификаторы.
- Любое ключевое утверждение в ответе должно быть подтверждено 1–3 цитатами из контекста.

ФОРМАТ ОТВЕТА (строго, 2 строки):
Ответ: <1–3 коротких предложения или "Не найдено в контексте.">
Цитаты: <1–3 цитаты вида [....] из контекста, либо "—" если не найдено>

assistant
<think>
Okay, let's tackle this question. The user is asking which LLM model is used in the project and why 4-bit quantization (AWQ INT4) was chosen. 

First, I need to find the LLM model mentioned. Looking through the context, there's a reference to "hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4" in [ОТЧЁТ Diamond.pdf#p=10]. That seems like the model they're using.

Next, the reason for choosing 4-bit quantization. The same paragraph mentions that it's because the model supports 4-bit quantization, which saves VRAM and speeds up inference. Also, they use vLLM for fast inference, which helps with scaling across different GPUs. 

I should check if there are other mentions. In [Diamond кт1.pdf#p=13], they talk about the model being small and quantization reducing memory size. But the main reason given in the first citation is about saving VRAM and speeding up inference. 

So the answer should include the model name and the reasons from the citations provided. Need to make sure not to add any extra info not in the context.
</think>

Ответ: Модель Meta-Llama-3.1-8B-Instruct-AWQ-INT4 выбрана из-за поддержки 4-битной квантизации, которая экономит видеопамять и ускоряет инференс.  
Цитаты: [ОТЧЁТ Diamond.pdf#p=10], [Diamond кт1.pdf#p=13]

=== Q5 ===
MODEL OUTPUT:
user
Ты строгий методист. Отвечай строго по контексту. Если ответа нет в контексте — напиши 'Не найдено в контексте'. Для ключевых утверждений приводи цитаты в формате [doc#p=N].

Ты строгий методист и проверяющий бенча.

ДАНО:
Ниже контекст из документа. Каждый фрагмент начинается с ссылки в квадратных скобках вида [CITATION].
Разрешено цитировать ТОЛЬКО эти ссылки, строго копируя их как есть.

ВОПРОС:
Какие типовые ошибки выявлялись при тестировании и какие меры перечислены для исправления?

КОНТЕКСТ:
[Diamond кт1.pdf#p=17] (folder=Diamond кт1, page=17)
Рекомендации по доработке проектов в индустрии
generate_stats_and_reports.py —generate_recommendations(...).
Алгоритм с моделью:
1.Читает:
stats.json,
competency_gaps_and_redundancy.json,
отфильтрованную матрицу competency_matrix_filtered.json,
при необходимости vacancies_processed.json(для примеров вакансий).
2.Для каждой индустрии готовит компактный набор данных:
топ компетенций из вакансий (top_demand);
топ компетенций из проектов (top_supply);
gaps(дефицитные компетенции);
redundancies(избыточные);
matches(где программа попадает в запрос индустрии);
Результат
несколько примеров вакансий по индустрии.
При этом: json файл
из списков выкидываются компетенции, название которых совпадает с названием индустрии (например, индустрия AI, компетенция AI).
3.Формирует промптRECOMMENDATIONS_PROMPT, в котором:
кратко описано, что за индустрия;
что такое спрос (из вакансий),
что такое предложение (из проектов),
какие обнаружены gapsи redundancies;
задача: дать 5–8 конкретных рекомендаций, как изменить/дополнить программу.
4.Вызывает llama.ask_one(prompt) для каждой индустрии, где есть хоть какие-то данные.
5.Пишет ответы в:
data/derived/recommendations.json—словарь industry-> текст рекомендаций;
лог data/derived/reco_log.txt —туда попадают промптыи сырые ответы LLM, чтобы можно было посмотреть ошибки агента.
Итого, по каждой индустрии получается текст рекомендаций LLM: что добавить, что усилить, что сократить.

---
[ОТЧЁТ Diamond.pdf#p=13] (folder=ОТЧЁТ Diamond, page=13)
3 Методология разработки, промежуточное тестирование и
выявленные ошибки
Методология: итеративная разработка “данные → извлечение →
проверка → улучшение”, потому что качество извлечения компетенций сильно
зависит от промпта, параметров инференса и качества исходных текстов.
Промежуточное тестирование проводилось на реальных вакансиях и
проектах: оценивалась корректность извлечённых компетенций и устойчивость
к “грязным” данным.
По результатам тестирования выявлялись типовые ошибки (пустые
ответы, дубли, нерелевантные компетенции, нестабильный формат), после чего
внедрялись меры: постобработка, уточнение промптов, ручная корректировка в
спорных случаях, эксперименты с параметрами генерации и подключение
QLoRA‑адаптера. Чаще всего возникали ошибки из-за “грязных данных” и
слишком больших промптов, поэтому внедрялись фильтры данных, а также
ограничивался промпт.
Отдельный класс проблем был связан с производительностью и
ограничениями вычислительных ресурсов (VRAM/батчинг/контекст), поэтому
вводились ограничения и настройки режима инференса для стабильной работы
пайплайна. Изначально инференс был построен на обычной не квантованной
Llama-3.1-8B на фреймворке Transformers[9]. Проблемы были очевидны:
огромное потребление памяти, крайне медленный инференс (до получаса),
низкое качества ответа, а также нужно было вручную выбирать размер батчей.
Для ускорения был использован фреймворк vllm, который автоматически
выбирает размер батчей; для уменьшения потребления памяти использовали
квантованную модель, а для повышения качества ответа выбирали модель типа
“Instruct”, то есть заточенные под четкие инструкции.

---
[ОТЧЁТ Diamond.pdf#p=2] (folder=ОТЧЁТ Diamond, page=2)
СОДЕРЖАНИЕ
1 Основная часть ..................................................................................................... 5
1.1 Работа участников: ........................................................................................ 5
1.2 Требования заказчика, backlog и план действий ....................................... 6
1.3 Аналоги проекта. ........................................................................................... 7
2 Архитектура программного продукта. ............................................................... 9
3 Методология разработки, промежуточное тестирование и выявленные
ошибки .................................................................................................................... 13
4 Планирование и распределение задач .............................................................. 14
ЗАКЛЮЧЕНИЕ ..................................................................................................... 15
СПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ............................................ 16
ПРИЛОЖЕНИЕ А ................................................................................................. 17
ВВЕДЕНИЕ

---
[Diamond кт1.pdf#p=20] (folder=Diamond кт1, page=20)
Получение данных
При помощи
API-ключей
происходит
процесс
извлечения
данных

---
[ОТЧЁТ Diamond.pdf#p=23] (folder=ОТЧЁТ Diamond, page=23)
Генерация индивидуального ценностного предложения
•
Создание персонализированного письма (email/LinkedIn)
•
Адаптация контента под специфику компании и ЛПР
•
Подготовка вариантов текста с разным тоном (формальный/неформальный)
•
Задача 3.2: Подготовка коммуникационных материалов
Формирование презентации о программе ПроКомпетенции
•
Создание FAQ для партнеров
•
Подготовка шаблонов соглашений
•
Описание выгод для компании-партнера
•
Задача 3.3: Планирование касаний
Разработка плана первого касания и фоллоу-апов
•
Определение оптимального времени отправки
•
Подготовка сценариев для разных ответов
•
Критическая точка эскалации № 3
Условие активации: Финальное утверждение писем.
Действие Человека:
Агент подготовил финальные тексты для ЛПР
•
Человек утверждает стилистику, тон и ключевое сообщение писем
•
Обеспечивает личное, "человеческое" качество первого контакта
•
перед отправкой
Вносит правки при необходимости
•
Одобряет отправку
•
Результат Фазы 3
Артефакт: Готовые к отправке Коммуникационные Пакеты
Утвержденный контент для каждой компании
•
Персонализированные письма
•
Презентационные материалы
•
План коммуникации и фоллоу-апов
•

---
[Функциональные_требования_агента.pdf#p=4] (folder=Функциональные_требования_агента, page=4)
• Генерация индивидуального ценностного предложения
• Создание персонализированного письма (email/LinkedIn)
• Адаптация контента под специфику компании и ЛПР
• Подготовка вариантов текста с разным тоном (формальный/неформальный)
Задача 3.2: Подготовка коммуникационных материалов
• Формирование презентации о программе ПроКомпетенции
• Создание FAQ для партнеров
• Подготовка шаблонов соглашений
• Описание выгод для компании-партнера
Задача 3.3: Планирование касаний
• Разработка плана первого касания и фоллоу-апов
• Определение оптимального времени отправки
• Подготовка сценариев для разных ответов
Критическая точка эскалации № 3
Условие активации: Финальное утверждение писем.
Действие Человека:
• Агент подготовил финальные тексты для ЛПР
• Человек утверждает стилистику, тон и ключевое сообщение писем
• Обеспечивает личное, "человеческое" качество первого контакта перед
отправкой
• Вносит правки при необходимости
• Одобряет отправку
Результат Фазы 3
Артефакт: Готовые к отправке Коммуникационные Пакеты
• Утвержденный контент для каждой компании
• Персонализированные письма
• Презентационные материалы
• План коммуникации и фоллоу-апов

ПРАВИЛА:
- Отвечай строго по контексту. Никаких знаний "из головы".
- Если прямого ответа нет в контексте — напиши ровно: Не найдено в контексте.
- Запрещено придумывать цитаты/страницы/идентификаторы.
- Любое ключевое утверждение в ответе должно быть подтверждено 1–3 цитатами из контекста.

ФОРМАТ ОТВЕТА (строго, 2 строки):
Ответ: <1–3 коротких предложения или "Не найдено в контексте.">
Цитаты: <1–3 цитаты вида [....] из контекста, либо "—" если не найдено>

assistant
<think>
Okay, let's tackle this query. The user is asking about the typical errors found during testing and the corrective measures taken. 

First, I need to look through the provided context to find mentions of errors and the measures to fix them. The main document here is "ОТЧЁТ Diamond.pdf" on page 13. 

Looking at that section, it mentions that during intermediate testing, typical errors were identified such as empty responses, duplicates, irrelevant competencies, and unstable formats. The corrective measures included post-processing, refining prompts, manual corrections in disputed cases, experiments with generation parameters, and using a QLoRA adapter. Also, issues with dirty data and large prompts led to implementing filters and limiting the prompt length. Additionally, performance and resource limitations (like VRAM, batching, context) required adjustments like using the vllm framework, quantized models, and selecting "Instruct" models for better quality.

I need to make sure I only reference the exact citations from the context. The user wants strict adherence to the provided documents, so I should check each part carefully. The other sections mention recommendations and data processing but not the errors and fixes. So the key points are from [ОТЧЁТ Diamond.pdf#p=13]. 

Now, structuring the answer: first list the errors, then the measures. Each point should be supported by the relevant citations. Make sure not to add any extra information beyond what's in the context.
</think>

Ответ: При тестировании выявлялись пустые ответы, дубли, нерелевантные компетенции, нестабильный формат, а также проблемы с производительностью из-за "грязных данных" и больших промптов. Меры включали постобработку, уточнение промптов, ручную корректировку, эксперименты с параметрами генерации, фильтры данных, ограничение промптов, использование квантованных моделей и фреймворка vllm.  
Цитаты: [ОТЧЁТ Diamond.pdf#p=13] (типовые ошибки: пустые ответы, дубли, нерелевантные компетенции, нестабильный формат; меры: постобработка, уточнение

=== Q6 ===
MODEL OUTPUT:
user
Ты строгий методист. Отвечай строго по контексту. Если ответа нет в контексте — напиши 'Не найдено в контексте'. Для ключевых утверждений приводи цитаты в формате [doc#p=N].

Ты строгий методист и проверяющий бенча.

ДАНО:
Ниже контекст из документа. Каждый фрагмент начинается с ссылки в квадратных скобках вида [CITATION].
Разрешено цитировать ТОЛЬКО эти ссылки, строго копируя их как есть.

ВОПРОС:
Перечисли функциональные требования FR-2.1–FR-2.6 для модуля поиска и скоринга компаний.

КОНТЕКСТ:
[ОТЧЁТ Diamond.pdf#p=29] (folder=ОТЧЁТ Diamond, page=29)
Связь проект-компетенция-партнер
•
Готовность к распределению студентов
•
Функциональные требования к системе
1. Модуль анализа индустрии и компетенций
FR-1.1: Система должна автоматически собирать данные о вакансиях из публич-
ных источников (HH.ru, Superjob, LinkedIn)
FR-1.2: Система должна извлекать компетенции из текстовых описаний вакансий
с использованием NLP
FR-1.3: Система должна формировать матрицу соответствия компетенций про-
граммы и индустрии
FR-1.4: Система должна генерировать визуализацию пробелов компетенций
(графики, таблицы)
FR-1.5: Система должна предоставлять интерфейс для утверждения приоритетных
областей поиска
2. Модуль поиска и скоринга компаний
FR-2.1: Система должна выполнять поиск компаний в заданной отрасли по базам
данных и открытым источникам
FR-2.2: Система должна собирать публичную информацию о компа-
ниях: технологический стек, проекты, размер
FR-2.3: Система должна рассчитывать скоринг компаний по алгоритму на основе
критериев соответствия (0-100 баллов)
FR-2.4: Система должна формировать ранжированные списки Top-10, Top-
100 компаний
FR-2.5: Система должна предоставлять интерфейс для верификации и
редактирования шорт-листа человеком
FR-2.6: Система должна формировать профили компаний с контактами ЛПР
3. Модуль генерации коммуникаций
FR-3.1: Система должна генерировать персонализированные письма для каждой
компании на основе ее профиля

---
[Функциональные_требования_агента.pdf#p=7] (folder=Функциональные_требования_агента, page=7)
• Связь проект-компетенция-партнер
• Готовность к распределению студентов
Функциональные требования к системе
1. Модуль анализа индустрии и компетенций
FR-1.1: Система должна автоматически собирать данные о вакансиях из публичных
источников (HH.ru, Superjob, LinkedIn)
FR-1.2: Система должна извлекать компетенции из текстовых описаний вакансий с
использованием NLP
FR-1.3: Система должна формировать матрицу соответствия компетенций программы
и индустрии
FR-1.4: Система должна генерировать визуализацию пробелов компетенций
(графики, таблицы)
FR-1.5: Система должна предоставлять интерфейс для утверждения приоритетных
областей поиска
2. Модуль поиска и скоринга компаний
FR-2.1: Система должна выполнять поиск компаний в заданной отрасли по базам
данных и открытым источникам
FR-2.2: Система должна собирать публичную информацию о компаниях:
технологический стек, проекты, размер
FR-2.3: Система должна рассчитывать скоринг компаний по алгоритму на основе
критериев соответствия (0-100 баллов)
FR-2.4: Система должна формировать ранжированные списки Top-10, Top-100
компаний
FR-2.5: Система должна предоставлять интерфейс для верификации и
редактирования шорт-листа человеком
FR-2.6: Система должна формировать профили компаний с контактами ЛПР
3. Модуль генерации коммуникаций
FR-3.1: Система должна генерировать персонализированные письма для каждой
компании на основе ее профиля
FR-3.2: Система должна создавать ценностные предложения с учетом специфики
компании

---
[Функциональные_требования_агента.pdf#p=9] (folder=Функциональные_требования_агента, page=9)
FR-6.4: Система должна применять когнитивные модели (RFT, NARS) для расширения
репертуара
FR-6.5: Система должна самостоятельно корректировать стратегии коммуникации на
основе обратной связи
7. Интерфейс и взаимодействие с человеком
FR-7.1: Система должна предоставлять дашборд с визуализацией прогресса по
фазам
FR-7.2: Система должна отправлять уведомления при достижении критических точек
эскалации
FR-7.3: Система должна предоставлять интерфейс для утверждения/отклонения
рекомендаций агента
FR-7.4: Система должна логировать все действия агента и решения человека
FR-7.5: Система должна поддерживать ручное вмешательство на любом этапе
Нефункциональные требования
NFR-1: Безопасность - система должна защищать персональные данные компаний и
студентов (GDPR, 152-ФЗ)
NFR-2: Масштабируемость - система должна обрабатывать до 1000 компаний
одновременно
NFR-3: Производительность - генерация письма не должна превышать 30 секунд
NFR-4: Доступность - система должна быть доступна 99% времени
NFR-5: Интеграции - система должна интегрироваться с API HeadHunter, LinkedIn,
email-сервисами
NFR-6: Языковая поддержка - система должна работать на русском и английском
языках
Технологический стек
Backend
• Python (FastAPI/Django) для основной логики
• PostgreSQL для реляционной БД
• Redis для кэширования
• Celery для асинхронных задач

---
[ОТЧЁТ Diamond.pdf#p=33] (folder=ОТЧЁТ Diamond, page=33)
FR-6.4: Система должна применять когнитивные модели (RFT, NARS) для расши-
рения репертуара
FR-6.5: Система должна самостоятельно корректировать стратегии коммуникации
на основе обратной связи
7. Интерфейс и взаимодействие с человеком
FR-7.1: Система должна предоставлять дашборд с визуализацией прогресса
по фазам
FR-7.2: Система должна отправлять уведомления при достижении критических то-
чек эскалации
FR-7.3: Система должна предоставлять интерфейс для утверждения/отклонения ре-
комендаций агента
FR-7.4: Система должна логировать все действия агента и решения человека
FR-7.5: Система должна поддерживать ручное вмешательство на любом этапе
Нефункциональные требования
NFR-1: Безопасность - система должна защищать персональные данные компа-
ний и студентов (GDPR, 152-ФЗ)
NFR-2: Масштабируемость - система должна обрабатывать до 1000 компаний од-
новременно
NFR-3: Производительность - генерация письма не должна превышать 30 секунд
NFR-4: Доступность - система должна быть доступна 99% времени
NFR-5: Интеграции - система должна интегрироваться с API HeadHunter,
LinkedIn, email-сервисами
NFR-6: Языковая поддержка - система должна работать на русском и ан-
глийском языках
Технологический стек
Backend
Python (FastAPI/Django) для основной логики
•
PostgreSQL для реляционной БД
•
Redis для кэширования
•

---
[Функциональные_требования_агента.pdf#p=8] (folder=Функциональные_требования_агента, page=8)
FR-3.3: Система должна поддерживать разные стили коммуникации
(формальный/неформальный)
FR-3.4: Система должна генерировать презентационные материалы и FAQ
FR-3.5: Система должна предоставлять интерфейс для утверждения текстов
коммуникаций человеком
FR-3.6: Система должна разрабатывать план касаний (первичное письмо + фоллоу-
апы)
4. Модуль Outreach и квалификации
FR-4.1: Система должна автоматически отправлять утвержденные письма через email
и LinkedIn API
FR-4.2: Система должна отслеживать статусы доставки и прочтения писем
FR-4.3: Система должна мониторить входящие ответы и категоризировать их
(интерес, отказ, вопросы)
FR-4.4: Система должна автоматически обрабатывать простые отказы и типовые
вопросы
FR-4.5: Система должна отправлять автоматические фоллоу-апы по расписанию
FR-4.6: Система должна эскалировать положительные ответы человеку для личного
контакта
FR-4.7: Система должна фиксировать результаты переговоров и соглашения
5. Модуль генерации проектов и ТЗ
FR-5.1: Система должна генерировать технические задания на основе деталей
соглашения с партнером
FR-5.2: Система должна размечать ТЗ по необходимым модулям и компетенциям
программы
FR-5.3: Система должна разбивать проекты по ролям с требованиями к навыкам
FR-5.4: Система должна интегрировать проекты в каталог системы ПроКомпетенции
FR-5.5: Система должна создавать связи проект-компетенция-партнер
6. Модуль памяти и адаптации агента
FR-6.1: Система должна хранить историю всех взаимодействий с компаниями и
результаты
FR-6.2: Система должна обучаться на основе успешных и неуспешных коммуникаций
FR-6.3: Система должна использовать QLORA адаптеры для улучшения генерации
текстов

---
[ОТЧЁТ Diamond.pdf#p=31] (folder=ОТЧЁТ Diamond, page=31)
FR-3.3: Система должна поддерживать разные стили коммуникации
(формальный/неформальный)
FR-3.4: Система должна генерировать презентационные материалы и FAQ
FR-3.5: Система должна предоставлять интерфейс для утверждения тек-
стов коммуникаций человеком
FR-3.6: Система должна разрабатывать план касаний (первичное письмо + фол-
лоу- апы)
4. Модуль Outreach и квалификации
FR-4.1: Система должна автоматически отправлять утвержденные письма через
email и LinkedIn API
FR-4.2: Система должна отслеживать статусы доставки и прочтения писем
FR-4.3: Система должна мониторить входящие ответы и категоризировать их
(интерес, отказ, вопросы)
FR-4.4: Система должна автоматически обрабатывать простые отказы и типовые
вопросы
FR-4.5: Система должна отправлять автоматические фоллоу-апы по расписанию
FR-4.6: Система должна эскалировать положительные ответы человеку для лич-
ного контакта
FR-4.7: Система должна фиксировать результаты переговоров и соглашения
5. Модуль генерации проектов и ТЗ
FR-5.1: Система должна генерировать технические задания на основе деталей со-
глашения с партнером
FR-5.2: Система должна размечать ТЗ по необходимым модулям и компетенциям
программы
FR-5.3: Система должна разбивать проекты по ролям с требованиями к навыкам
FR-5.4: Система должна интегрировать проекты в каталог системы ПроКомпетен-
ции
FR-5.5: Система должна создавать связи проект-компетенция-партнер
6. Модуль памяти и адаптации агента
FR-6.1: Система должна хранить историю всех взаимодействий с компаниями и
результаты

ПРАВИЛА:
- Отвечай строго по контексту. Никаких знаний "из головы".
- Если прямого ответа нет в контексте — напиши ровно: Не найдено в контексте.
- Запрещено придумывать цитаты/страницы/идентификаторы.
- Любое ключевое утверждение в ответе должно быть подтверждено 1–3 цитатами из контекста.

ФОРМАТ ОТВЕТА (строго, 2 строки):
Ответ: <1–3 коротких предложения или "Не найдено в контексте.">
Цитаты: <1–3 цитаты вида [....] из контекста, либо "—" если не найдено>

assistant
<think>
Хорошо, мне нужно перечислить функциональные требования FR-2.1–FR-2.6 для модуля поиска и скоринга компаний. Давайте посмотрю на контекст.

В первом документе [ОТЧЁТ Diamond.pdf#p=29] и [Функциональные_требования_агента.pdf#p=7] говорится о модуле поиска и скоринга компаний. В них указаны FR-2.1 до FR-2.6. Например, FR-2.1 — поиск компаний по отрасли, FR-2.2 — сбор информации, FR-2.3 — скоринг, FR-2.4 — ранжирование, FR-2.5 — интерфейс для редактирования шорт-листа, FR-2.6 — профили с контактами ЛПР. 

Проверяю, есть ли все эти пункты в контексте. В [Функциональные_требования_агента.pdf#p=7] точно указаны все FR-2.1–FR-2.6. Также в других частях документов, например, [ОТЧЁТ Diamond.pdf#p=33], упоминаются некоторые из них, но основная информация по FR-2.1–FR-2.6 находится в [Функциональные_требования_агента.pdf#p=7]. 

Таким образом, можно перечислить все шесть пунктов, сославшись на соответствующие цитаты из этого документа.
</think>

Ответ: Функциональные требования FR-2.1–FR-2.6 для модуля поиска и скоринга компаний:  
FR-2.1: Поиск компаний в заданной отрасли [Функциональные_требования_агента.pdf#p=7].  
FR-2.2: Сбор публичной информации о компаниях [Функциональные_требования_агента.pdf#p=7].  
FR-2.3: Расчёт скоринга по алгоритму [Функциональные_требования_агента.pdf#p=7].  
FR-2.

=== Q7 ===
MODEL OUTPUT:
user
Ты строгий методист. Отвечай строго по контексту. Если ответа нет в контексте — напиши 'Не найдено в контексте'. Для ключевых утверждений приводи цитаты в формате [doc#p=N].

Ты строгий методист и проверяющий бенча.

ДАНО:
Ниже контекст из документа. Каждый фрагмент начинается с ссылки в квадратных скобках вида [CITATION].
Разрешено цитировать ТОЛЬКО эти ссылки, строго копируя их как есть.

ВОПРОС:
Перечисли нефункциональные требования NFR-1–NFR-6.

КОНТЕКСТ:
[Функциональные_требования_агента.pdf#p=9] (folder=Функциональные_требования_агента, page=9)
FR-6.4: Система должна применять когнитивные модели (RFT, NARS) для расширения
репертуара
FR-6.5: Система должна самостоятельно корректировать стратегии коммуникации на
основе обратной связи
7. Интерфейс и взаимодействие с человеком
FR-7.1: Система должна предоставлять дашборд с визуализацией прогресса по
фазам
FR-7.2: Система должна отправлять уведомления при достижении критических точек
эскалации
FR-7.3: Система должна предоставлять интерфейс для утверждения/отклонения
рекомендаций агента
FR-7.4: Система должна логировать все действия агента и решения человека
FR-7.5: Система должна поддерживать ручное вмешательство на любом этапе
Нефункциональные требования
NFR-1: Безопасность - система должна защищать персональные данные компаний и
студентов (GDPR, 152-ФЗ)
NFR-2: Масштабируемость - система должна обрабатывать до 1000 компаний
одновременно
NFR-3: Производительность - генерация письма не должна превышать 30 секунд
NFR-4: Доступность - система должна быть доступна 99% времени
NFR-5: Интеграции - система должна интегрироваться с API HeadHunter, LinkedIn,
email-сервисами
NFR-6: Языковая поддержка - система должна работать на русском и английском
языках
Технологический стек
Backend
• Python (FastAPI/Django) для основной логики
• PostgreSQL для реляционной БД
• Redis для кэширования
• Celery для асинхронных задач

---
[ОТЧЁТ Diamond.pdf#p=33] (folder=ОТЧЁТ Diamond, page=33)
FR-6.4: Система должна применять когнитивные модели (RFT, NARS) для расши-
рения репертуара
FR-6.5: Система должна самостоятельно корректировать стратегии коммуникации
на основе обратной связи
7. Интерфейс и взаимодействие с человеком
FR-7.1: Система должна предоставлять дашборд с визуализацией прогресса
по фазам
FR-7.2: Система должна отправлять уведомления при достижении критических то-
чек эскалации
FR-7.3: Система должна предоставлять интерфейс для утверждения/отклонения ре-
комендаций агента
FR-7.4: Система должна логировать все действия агента и решения человека
FR-7.5: Система должна поддерживать ручное вмешательство на любом этапе
Нефункциональные требования
NFR-1: Безопасность - система должна защищать персональные данные компа-
ний и студентов (GDPR, 152-ФЗ)
NFR-2: Масштабируемость - система должна обрабатывать до 1000 компаний од-
новременно
NFR-3: Производительность - генерация письма не должна превышать 30 секунд
NFR-4: Доступность - система должна быть доступна 99% времени
NFR-5: Интеграции - система должна интегрироваться с API HeadHunter,
LinkedIn, email-сервисами
NFR-6: Языковая поддержка - система должна работать на русском и ан-
глийском языках
Технологический стек
Backend
Python (FastAPI/Django) для основной логики
•
PostgreSQL для реляционной БД
•
Redis для кэширования
•

---
[ОТЧЁТ Diamond.pdf#p=2] (folder=ОТЧЁТ Diamond, page=2)
СОДЕРЖАНИЕ
1 Основная часть ..................................................................................................... 5
1.1 Работа участников: ........................................................................................ 5
1.2 Требования заказчика, backlog и план действий ....................................... 6
1.3 Аналоги проекта. ........................................................................................... 7
2 Архитектура программного продукта. ............................................................... 9
3 Методология разработки, промежуточное тестирование и выявленные
ошибки .................................................................................................................... 13
4 Планирование и распределение задач .............................................................. 14
ЗАКЛЮЧЕНИЕ ..................................................................................................... 15
СПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ............................................ 16
ПРИЛОЖЕНИЕ А ................................................................................................. 17
ВВЕДЕНИЕ

---
[ОТЧЁТ Diamond.pdf#p=6] (folder=ОТЧЁТ Diamond, page=6)
4.2) Дизайн презентационных материалов и участие в разработке
пользовательских сценариев взаимодействия с результатами.
1.2 Требования заказчика, backlog и план действий
Требования заказчика:
1.1) Получать регулярный и воспроизводимый анализ индустриальных
компетенций на основе данных рынка труда.

---
[ОТЧЁТ Diamond.pdf#p=29] (folder=ОТЧЁТ Diamond, page=29)
Связь проект-компетенция-партнер
•
Готовность к распределению студентов
•
Функциональные требования к системе
1. Модуль анализа индустрии и компетенций
FR-1.1: Система должна автоматически собирать данные о вакансиях из публич-
ных источников (HH.ru, Superjob, LinkedIn)
FR-1.2: Система должна извлекать компетенции из текстовых описаний вакансий
с использованием NLP
FR-1.3: Система должна формировать матрицу соответствия компетенций про-
граммы и индустрии
FR-1.4: Система должна генерировать визуализацию пробелов компетенций
(графики, таблицы)
FR-1.5: Система должна предоставлять интерфейс для утверждения приоритетных
областей поиска
2. Модуль поиска и скоринга компаний
FR-2.1: Система должна выполнять поиск компаний в заданной отрасли по базам
данных и открытым источникам
FR-2.2: Система должна собирать публичную информацию о компа-
ниях: технологический стек, проекты, размер
FR-2.3: Система должна рассчитывать скоринг компаний по алгоритму на основе
критериев соответствия (0-100 баллов)
FR-2.4: Система должна формировать ранжированные списки Top-10, Top-
100 компаний
FR-2.5: Система должна предоставлять интерфейс для верификации и
редактирования шорт-листа человеком
FR-2.6: Система должна формировать профили компаний с контактами ЛПР
3. Модуль генерации коммуникаций
FR-3.1: Система должна генерировать персонализированные письма для каждой
компании на основе ее профиля

---
[Функциональные_требования_агента.pdf#p=7] (folder=Функциональные_требования_агента, page=7)
• Связь проект-компетенция-партнер
• Готовность к распределению студентов
Функциональные требования к системе
1. Модуль анализа индустрии и компетенций
FR-1.1: Система должна автоматически собирать данные о вакансиях из публичных
источников (HH.ru, Superjob, LinkedIn)
FR-1.2: Система должна извлекать компетенции из текстовых описаний вакансий с
использованием NLP
FR-1.3: Система должна формировать матрицу соответствия компетенций программы
и индустрии
FR-1.4: Система должна генерировать визуализацию пробелов компетенций
(графики, таблицы)
FR-1.5: Система должна предоставлять интерфейс для утверждения приоритетных
областей поиска
2. Модуль поиска и скоринга компаний
FR-2.1: Система должна выполнять поиск компаний в заданной отрасли по базам
данных и открытым источникам
FR-2.2: Система должна собирать публичную информацию о компаниях:
технологический стек, проекты, размер
FR-2.3: Система должна рассчитывать скоринг компаний по алгоритму на основе
критериев соответствия (0-100 баллов)
FR-2.4: Система должна формировать ранжированные списки Top-10, Top-100
компаний
FR-2.5: Система должна предоставлять интерфейс для верификации и
редактирования шорт-листа человеком
FR-2.6: Система должна формировать профили компаний с контактами ЛПР
3. Модуль генерации коммуникаций
FR-3.1: Система должна генерировать персонализированные письма для каждой
компании на основе ее профиля
FR-3.2: Система должна создавать ценностные предложения с учетом специфики
компании

ПРАВИЛА:
- Отвечай строго по контексту. Никаких знаний "из головы".
- Если прямого ответа нет в контексте — напиши ровно: Не найдено в контексте.
- Запрещено придумывать цитаты/страницы/идентификаторы.
- Любое ключевое утверждение в ответе должно быть подтверждено 1–3 цитатами из контекста.

ФОРМАТ ОТВЕТА (строго, 2 строки):
Ответ: <1–3 коротких предложения или "Не найдено в контексте.">
Цитаты: <1–3 цитаты вида [....] из контекста, либо "—" если не найдено>

assistant
<think>
Хорошо, пользователь просит перечислить нефункциональные требования NFR-1–NFR-6. Нужно строго следовать контексту, который предоставлен. 

Сначала проверю, есть ли в контексте раздел с нефункциональными требованиями. Вижу, что в двух файлах — [Функциональные_требования_агента.pdf#p=9] и [ОТЧЁТ Diamond.pdf#p=33] — есть раздел "Нефункциональные требования", где указаны NFR-1 до NFR-6. 

В первом документе, на странице 9, после функциональных требований FR-6.4 и FR-6.5, идет раздел "Нефункциональные требования" с NFR-1 по NFR-6. То же самое повторяется во втором документе, [ОТЧЁТ Diamond.pdf#p=33], где также перечислены NFR-1–NFR-6. 

Теперь нужно перечислить каждый NFR с указанием цитат. Проверю, чтобы каждое требование было правильно сформулировано и соответствовало контексту. 

NFR-1: Безопасность — защита персональных данных (GDPR, 152-ФЗ). Цитата из первого документа [Функциональные_требования_агента.pdf#p=9]. 

NFR-2: Масштабируемость — обработка до 1000 компаний. Тоже из первого документа. 

NFR-3: Производительность — генерация письма не более 30 секунд. 

NFR-4: Доступность — 99% времени. 

NFR-5: Интеграции с API HeadHunter, LinkedIn, email-сервисами. 

NFR-6: Языковая поддержка — русский и английский. 

Все эти пункты есть в обоих документах, поэтому можно использовать любую из ссылок. Но нужно выбрать правильные цитаты. Например, для NFR-1 и NFR-2 можно

=== Q8 ===
MODEL OUTPUT:
user
Ты строгий методист. Отвечай строго по контексту. Если ответа нет в контексте — напиши 'Не найдено в контексте'. Для ключевых утверждений приводи цитаты в формате [doc#p=N].

Ты строгий методист и проверяющий бенча.

ДАНО:
Ниже контекст из документа. Каждый фрагмент начинается с ссылки в квадратных скобках вида [CITATION].
Разрешено цитировать ТОЛЬКО эти ссылки, строго копируя их как есть.

ВОПРОС:
Перечисли KPI-1–KPI-6 критерии успеха проекта (с порогами/числами).

КОНТЕКСТ:
[Функциональные_требования_агента.pdf#p=11] (folder=Функциональные_требования_агента, page=11)
• Модуль поиска компаний с базовым скорингом
• Шаблонная генерация писем
• Ручная отправка и мониторинг
• Простое хранилище данных
Этап 2: Автоматизация
• Автоматический Outreach и фоллоу-апы
• Интеграция с email/LinkedIn API
• Улучшенная персонализация текстов
• Дашборд с аналитикой
Этап 3: Интеллектуальная память
• Внедрение QLORA адаптеров
• Разработка модели поведенческих данных
• Интеграция RFT/NARS компонентов
• Самообучение на основе обратной связи
Этап 4: Масштабирование
• Оптимизация производительности
• Расширение источников данных
• Мультиязычность
• Интеграция с системой ПроКомпетенции
Критерии успеха проекта
KPI-1: Формирование пула 100+ потенциальных партнеров за 1 месяц
KPI-2: Процент откликов на письма > 15%
KPI-3: Заключение партнерских соглашений с 10+ компаниями за семестр
KPI-4: Формирование каталога из 20+ реальных проектов
KPI-5: Сокращение времени на поиск партнера с 2 месяцев до 2 недель
KPI-6: Удовлетворенность студентов качеством проектов > 4/5

---
[ОТЧЁТ Diamond.pdf#p=37] (folder=ОТЧЁТ Diamond, page=37)
Модуль поиска компаний с базовым скорингом
•
Шаблонная генерация писем
•
Ручная отправка и мониторинг
•
Простое хранилище данных
•
Этап 2: Автоматизация
Автоматический Outreach и фоллоу-апы
•
Интеграция с email/LinkedIn API
•
Улучшенная персонализация текстов
•
Дашборд с аналитикой
•
Этап 3: Интеллектуальная память
Внедрение QLORA адаптеров
•
Разработка модели поведенческих данных
•
Интеграция RFT/NARS компонентов
•
Самообучение на основе обратной связи
•
Этап 4: Масштабирование
Оптимизация производительности
•
Расширение источников данных
•
Мультиязычность
•
Интеграция с системой ПроКомпетенции
•
Критерии успеха проекта
KPI-1: Формирование пула 100+ потенциальных партнеров за 1 месяц
KPI-2: Процент откликов на письма > 15%
KPI-3: Заключение партнерских соглашений с 10+ компаниями за семестр
KPI-4: Формирование каталога из 20+ реальных проектов
KPI-5: Сокращение времени на поиск партнера с 2 месяцев до 2 недель

---
[ОТЧЁТ Diamond.pdf#p=38] (folder=ОТЧЁТ Diamond, page=38)
KPI-6: Удовлетворенность студентов качеством проектов > 4/5
38

---
[Diamond кт1.pdf#p=5] (folder=Diamond кт1, page=5)
Система работы команды
Заказчик → Гиль К. → Ивашкина Е. → Гордеев Р. → Бухарбаев И.
↓
Бухарбаев И. → Гордеев Р. → Гиль К. → Заказчик
Конкретные примеры передачи:
● Гиль →Ивашкина: "Бизнес-требования с метриками успеха"
● Ивашкина → Гордеев:"User Stories + критерии приемки"
● Бухарбаев → Гордеев:"ML-модель в Docker + API документация"
● Гордеев → Гиль: "Работающий бот + чек-лист проверки"

---
[ОТЧЁТ Diamond.pdf#p=2] (folder=ОТЧЁТ Diamond, page=2)
СОДЕРЖАНИЕ
1 Основная часть ..................................................................................................... 5
1.1 Работа участников: ........................................................................................ 5
1.2 Требования заказчика, backlog и план действий ....................................... 6
1.3 Аналоги проекта. ........................................................................................... 7
2 Архитектура программного продукта. ............................................................... 9
3 Методология разработки, промежуточное тестирование и выявленные
ошибки .................................................................................................................... 13
4 Планирование и распределение задач .............................................................. 14
ЗАКЛЮЧЕНИЕ ..................................................................................................... 15
СПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ............................................ 16
ПРИЛОЖЕНИЕ А ................................................................................................. 17
ВВЕДЕНИЕ

---
[ОТЧЁТ Diamond.pdf#p=7] (folder=ОТЧЁТ Diamond, page=7)
1.2) Видеть сопоставление “индустрия ↔ программа/проекты” в
понятном виде (матрица соответствия, пробелы, избыточность).
1.3) Получать рекомендации для корректировки программы или
изменения фокуса, если расхождение с индустрией критично.
Backlog, реализованный за семестр:
2.1) Сбор вакансий с hh.ru[3] и SuperJob[4] при помощи API.
2.2) Извлечение компетенций из вакансий с помощью LLM и
постобработки результатов.
2.3) Извлечение компетенций из учебных проектов/описаний
«ПроКомпетенции» с помощью LLM.
2.4) Сопоставление компетенций и построение матрицы соответствия,
вычисление пробелов и совпадений.
2.5) Генерация статистики, графиков и рекомендаций по результатам
сопоставления.
2.6) Обучение и интеграция QLoRA‑адаптера, стабилизирующего ответы
в домене задачи.
2.7) Разработка интерфейса для взаимодействия с агентом и работы с
результатами.
1.3 Аналоги проекта.
Существующие инструменты компетенций и HR‑аналитики часто дают
статистику и отчёты, но не обеспечивают качественное извлечение
компетенций из неструктурированного текста без LLM и не адаптированы под
специфику проектного обучения.

ПРАВИЛА:
- Отвечай строго по контексту. Никаких знаний "из головы".
- Если прямого ответа нет в контексте — напиши ровно: Не найдено в контексте.
- Запрещено придумывать цитаты/страницы/идентификаторы.
- Любое ключевое утверждение в ответе должно быть подтверждено 1–3 цитатами из контекста.

ФОРМАТ ОТВЕТА (строго, 2 строки):
Ответ: <1–3 коротких предложения или "Не найдено в контексте.">
Цитаты: <1–3 цитаты вида [....] из контекста, либо "—" если не найдено>

assistant
<think>
Хорошо, давайте разберемся с этим вопросом. Пользователь просит перечислить KPI-1 до KPI-6 критерии успеха проекта с порогами/числами. Нужно строго следовать контексту, привести цитаты, если они есть, иначе написать "Не найдено в контексте".

Сначала посмотрю на предоставленный контекст. В первом документе [Функциональные_требования_агента.pdf#p=11] есть раздел "Критерии успеха проекта", где указаны KPI-1 до KPI-5. Но KPI-6 там нет. Затем в [ОТЧЁТ Diamond.pdf#p=37] также перечислены KPI-1 до KPI-5, и в [ОТЧЁТ Diamond.pdf#p=38] упоминается KPI-6. То есть все шесть KPI есть в контексте.

Теперь проверю каждое KPI:

KPI-1: Формирование пула 100+ потенциальных партнеров за 1 месяц. Цитата из [ОТЧЁТ Diamond.pdf#p=37].

KPI-2: Процент откликов на письма > 15%. Тоже из [ОТЧЁТ Diamond.pdf#p=37].

KPI-3: Заключение партнерских соглашений с 10+ компаниями за семестр. В том же документе.

KPI-4: Формирование каталога из 20+ реальных проектов. Тоже в [ОТЧЁТ Diamond.pdf#p=37].

KPI-5: Сокращение времени на поиск партнера с 2 месяцев до 2 недель. Здесь же.

KPI-6: Удовлетворенность студентов качеством проектов > 4/5. В [ОТЧЁТ Diamond.pdf#p=38].

Все шесть KPI указаны в контексте, поэтому ответ будет содержать их перечисление с соответствующими цитатами. Нужно убедиться, что каждая цифра и пор

=== Q9 ===
MODEL OUTPUT:
user
Ты строгий методист. Отвечай строго по контексту. Если ответа нет в контексте — напиши 'Не найдено в контексте'. Для ключевых утверждений приводи цитаты в формате [doc#p=N].

Ты строгий методист и проверяющий бенча.

ДАНО:
Ниже контекст из документа. Каждый фрагмент начинается с ссылки в квадратных скобках вида [CITATION].
Разрешено цитировать ТОЛЬКО эти ссылки, строго копируя их как есть.

ВОПРОС:
Какие самые востребованные навыки и какие дефицитные компетенции в проектах перечислены?

КОНТЕКСТ:
[Diamond кт1.pdf#p=7] (folder=Diamond кт1, page=7)
Анализ данных
Проанализированы:
● ✅106+ проектов с ПроКомпетенций
● ✅300+ вакансий с SuperJob API
● ✅Индустрии и компетенции проектов
● ✅Требования рынка труда
Ключевые инсайты:
● Самые востребованные навыки: Python, Data Analysis, ML
● Дефицитные компетенции в проектах: Product Management, UX/UI
● Успешные команды: 3-4 человека с complementary skills

---
[Diamond кт1.pdf#p=17] (folder=Diamond кт1, page=17)
Рекомендации по доработке проектов в индустрии
generate_stats_and_reports.py —generate_recommendations(...).
Алгоритм с моделью:
1.Читает:
stats.json,
competency_gaps_and_redundancy.json,
отфильтрованную матрицу competency_matrix_filtered.json,
при необходимости vacancies_processed.json(для примеров вакансий).
2.Для каждой индустрии готовит компактный набор данных:
топ компетенций из вакансий (top_demand);
топ компетенций из проектов (top_supply);
gaps(дефицитные компетенции);
redundancies(избыточные);
matches(где программа попадает в запрос индустрии);
Результат
несколько примеров вакансий по индустрии.
При этом: json файл
из списков выкидываются компетенции, название которых совпадает с названием индустрии (например, индустрия AI, компетенция AI).
3.Формирует промптRECOMMENDATIONS_PROMPT, в котором:
кратко описано, что за индустрия;
что такое спрос (из вакансий),
что такое предложение (из проектов),
какие обнаружены gapsи redundancies;
задача: дать 5–8 конкретных рекомендаций, как изменить/дополнить программу.
4.Вызывает llama.ask_one(prompt) для каждой индустрии, где есть хоть какие-то данные.
5.Пишет ответы в:
data/derived/recommendations.json—словарь industry-> текст рекомендаций;
лог data/derived/reco_log.txt —туда попадают промптыи сырые ответы LLM, чтобы можно было посмотреть ошибки агента.
Итого, по каждой индустрии получается текст рекомендаций LLM: что добавить, что усилить, что сократить.

---
[ОТЧЁТ Diamond.pdf#p=12] (folder=ОТЧЁТ Diamond, page=12)
Рисунок 4 - Пример обучения QLoRA-адаптера
Также в интерфейсе можно создать матрицы соответствия компетенций,
статистику и рекомендации по индустриям. Если в вакансиях и в проектах
встречается компетенция, это будет отражено в матрице компетенций. В
статистике учитывается сколько раз компетенция встречалась в проектах или
вакансиях и на основании этого строится график.
Рисунок 5 - Статистика компетенций в проектах
LLM анализирует компетенции по индустриям и выносит вердикт в виде
рекомендаций, если есть дефицитные или избыточные компетенции.
Рисунок 6 - Примеры рекомендаций по индустриям

---
[ОТЧЁТ Diamond.pdf#p=8] (folder=ОТЧЁТ Diamond, page=8)
Универсальные LLM‑чатботы способны отвечать на запросы и извлекать
навыки, но без доменной адаптации и контроля качества дают нестабильные
результаты и плохо масштабируются на большие массивы вакансий/проектов.
Фактически прямых цифровых аналогов, которые анализируют проекты
из проектных платформ нет и сверяют с вакансиями по компетенциям нет.

---
[ОТЧЁТ Diamond.pdf#p=13] (folder=ОТЧЁТ Diamond, page=13)
3 Методология разработки, промежуточное тестирование и
выявленные ошибки
Методология: итеративная разработка “данные → извлечение →
проверка → улучшение”, потому что качество извлечения компетенций сильно
зависит от промпта, параметров инференса и качества исходных текстов.
Промежуточное тестирование проводилось на реальных вакансиях и
проектах: оценивалась корректность извлечённых компетенций и устойчивость
к “грязным” данным.
По результатам тестирования выявлялись типовые ошибки (пустые
ответы, дубли, нерелевантные компетенции, нестабильный формат), после чего
внедрялись меры: постобработка, уточнение промптов, ручная корректировка в
спорных случаях, эксперименты с параметрами генерации и подключение
QLoRA‑адаптера. Чаще всего возникали ошибки из-за “грязных данных” и
слишком больших промптов, поэтому внедрялись фильтры данных, а также
ограничивался промпт.
Отдельный класс проблем был связан с производительностью и
ограничениями вычислительных ресурсов (VRAM/батчинг/контекст), поэтому
вводились ограничения и настройки режима инференса для стабильной работы
пайплайна. Изначально инференс был построен на обычной не квантованной
Llama-3.1-8B на фреймворке Transformers[9]. Проблемы были очевидны:
огромное потребление памяти, крайне медленный инференс (до получаса),
низкое качества ответа, а также нужно было вручную выбирать размер батчей.
Для ускорения был использован фреймворк vllm, который автоматически
выбирает размер батчей; для уменьшения потребления памяти использовали
квантованную модель, а для повышения качества ответа выбирали модель типа
“Instruct”, то есть заточенные под четкие инструкции.

---
[ОТЧЁТ Diamond.pdf#p=9] (folder=ОТЧЁТ Diamond, page=9)
2 Архитектура программного продукта.
Так как у «ПроКомпетенции» нет API, был реализован парсер[6] в виде
расширения для браузера. Оно собирает информацию о всех проектах, которые
есть на платформе. У каждого проекта есть свой собственный ID, список
которых можно увидеть в коде страницы «ПроКомпетенции». Так как разным
пользователям видны разные проекты, ID можно указывать вручную.
Подразумевается, что парсер может использоваться не более, чем раз в семестр,
так как проекты обновляются каждый семестр, поэтому парсер был сделан
максимально простым.
Рисунок 1 - Сбор данных проектов при помощи парсера
Данные с парсера сохраняются в виде JSON файла для удобной работы с
ними.
Далее весь проект реализован неразрывно одним репозиторием.
У hh.ru и SuperJob есть свои API, поэтому сборщики вакансий
реализованы прямо в проекте. Поиск вакансий происходит по ключевым
словам.

ПРАВИЛА:
- Отвечай строго по контексту. Никаких знаний "из головы".
- Если прямого ответа нет в контексте — напиши ровно: Не найдено в контексте.
- Запрещено придумывать цитаты/страницы/идентификаторы.
- Любое ключевое утверждение в ответе должно быть подтверждено 1–3 цитатами из контекста.

ФОРМАТ ОТВЕТА (строго, 2 строки):
Ответ: <1–3 коротких предложения или "Не найдено в контексте.">
Цитаты: <1–3 цитаты вида [....] из контекста, либо "—" если не найдено>

assistant
<think>
Хорошо, давайте разберемся с этим вопросом. Пользователь спрашивает, какие самые востребованные навыки и какие дефицитные компетенции в проектах перечислены. Нужно ответить строго по контексту, используя только предоставленные цитаты.

Сначала я просмотрю все фрагменты контекста. В первом документе, [Diamond кт1.pdf#p=7], говорится, что анализ показал самые востребованные навыки: Python, Data Analysis, ML. Также упоминаются дефицитные компетенции: Product Management, UX/UI. Это прямо ответ на вопрос. 

Другие части контекста, такие как [Diamond кт1.pdf#p=17] и [ОТЧЁТ Diamond.pdf#p=12], говорят о рекомендациях и методологии, но не добавляют новых данных по востребованным навыкам или дефицитным компетенциям. Остальные разделы описывают техническую реализацию, но не содержат информации, которая ответила бы на вопрос. 

Проверяю, есть ли другие упоминания. В [ОТЧЁТ Diamond.pdf#p=8] говорится о том, что нет прямых аналогов, которые анализируют проекты и вакансии, но это не относится к навыкам. В [ОТЧЁТ Diamond.pdf#p=13] описываются ошибки и методология, но опять же, не добавляют новых данных. 

Таким образом, только первый фрагмент содержит необходимую информацию. Нужно точно повторить цитаты из этого источника. Проверяю, что в ответе не используется информация из других частей, и цитаты правильно указаны. Ответ должен быть коротким, с двумя строками: ответ и цитаты. Убедиться, что нет лишних деталей или придуманных утверждений.
</think>

Ответ: Самые востребованные навыки: Python, Data Analysis, ML. Дефицитные компетенции: Product Management,

=== Q10 ===
MODEL OUTPUT:
user
Ты строгий методист. Отвечай строго по контексту. Если ответа нет в контексте — напиши 'Не найдено в контексте'. Для ключевых утверждений приводи цитаты в формате [doc#p=N].

Ты строгий методист и проверяющий бенча.

ДАНО:
Ниже контекст из документа. Каждый фрагмент начинается с ссылки в квадратных скобках вида [CITATION].
Разрешено цитировать ТОЛЬКО эти ссылки, строго копируя их как есть.

ВОПРОС:
Какие задачи на следующую КТ перечислены (оба блока)?

КОНТЕКСТ:
[Diamond кт1.pdf#p=10] (folder=Diamond кт1, page=10)
Задачи на следующюю кт
ФОРМИРОВАНИЕ ПУЛА И СКОРИНГ
1) Поиск компаний в утвержденной отрасли
2) Скоринг и ранжирование компаний
3) Подготовка профилей компаний
СТРАТЕГИЧЕСКАЯ КОММУНИКАЦИЯ
1) Генерация персонализированных черновиков
2) Подготовка коммуникационных материалов
3) Планирование касаний

---
[Diamond кт1.pdf#p=17] (folder=Diamond кт1, page=17)
Рекомендации по доработке проектов в индустрии
generate_stats_and_reports.py —generate_recommendations(...).
Алгоритм с моделью:
1.Читает:
stats.json,
competency_gaps_and_redundancy.json,
отфильтрованную матрицу competency_matrix_filtered.json,
при необходимости vacancies_processed.json(для примеров вакансий).
2.Для каждой индустрии готовит компактный набор данных:
топ компетенций из вакансий (top_demand);
топ компетенций из проектов (top_supply);
gaps(дефицитные компетенции);
redundancies(избыточные);
matches(где программа попадает в запрос индустрии);
Результат
несколько примеров вакансий по индустрии.
При этом: json файл
из списков выкидываются компетенции, название которых совпадает с названием индустрии (например, индустрия AI, компетенция AI).
3.Формирует промптRECOMMENDATIONS_PROMPT, в котором:
кратко описано, что за индустрия;
что такое спрос (из вакансий),
что такое предложение (из проектов),
какие обнаружены gapsи redundancies;
задача: дать 5–8 конкретных рекомендаций, как изменить/дополнить программу.
4.Вызывает llama.ask_one(prompt) для каждой индустрии, где есть хоть какие-то данные.
5.Пишет ответы в:
data/derived/recommendations.json—словарь industry-> текст рекомендаций;
лог data/derived/reco_log.txt —туда попадают промптыи сырые ответы LLM, чтобы можно было посмотреть ошибки агента.
Итого, по каждой индустрии получается текст рекомендаций LLM: что добавить, что усилить, что сократить.

---
[ОТЧЁТ Diamond.pdf#p=4] (folder=ОТЧЁТ Diamond, page=4)
4) Обученные и интегрированные QLoRA‑адаптеры, позволяющие
адаптировать LLM под домен задачи (компетенции, вакансии, учебные
проекты) и повысить устойчивость извлечения навыков/формата
ответов в сравнении с “чистой” базовой моделью.
5) Интерфейс для удобного взаимодействия с агентом и результатов
анализа, включая возможность просмотра и ручной корректировки
спорных/некорректных ответов LLM на промежуточных этапах.

---
[ОТЧЁТ Diamond.pdf#p=3] (folder=ОТЧЁТ Diamond, page=3)
Цель проекта — разработать систему управления опытом (реляционной
памяти) для ИИ‑агентских систем на продукте «ПроКомпетенции»[1], чтобы
повысить качество сопровождения проектного обучения за счёт
автоматизированного анализа компетенций, выявления пробелов и генерации
рекомендаций.
В рамках семестра были поставлены команда выполняла следующие
задачи: подготовка основы для ИИ‑агента сопровождения проектного обучения
на платформе «ПроКомпетенции»: выбрать технологический стек и модель
агента, обеспечить адаптацию LLM[2] под домен проекта с помощью
QLoRA[3], а также реализовать интерфейс для удобного взаимодействия
пользователей с агентом.
Актуальность проекта обусловлена тем, что образовательные программы
проектного обучения быстро сталкиваются с разрывом между тем, чему
обучают, и тем, что требуется рынку труда; это приводит к снижению
практической ценности обучения и повышает нагрузку на организаторов,
которым нужно регулярно обновлять содержание и контролировать
соответствие компетенций.
Область применения — цифровая платформа сопровождения проектного
обучения «ПроКомпетенции». Потенциально может интегрироваться на любых
проектных платформах, так как агент анализирует проекты не зависимо от
платформы.
Ожидаемые результаты и планируемые достижения (по итогам семестра):
1) Рабочий прототип ИИ‑агента (LLM‑ядро + сценарии) для
сопровождения проектного обучения на платформе
«ПроКомпетенции», ориентированный на задачи анализа компетенций
и подготовки текстовых выводов.
2) Работа с данными: сбор и подготовка данных о вакансиях, извлечение
компетенций из вакансий и учебных проектов, сопоставление спроса и
предложения по индустриям, формирование матриц соответствия.
3) Набор артефактов аналитики, пригодных для принятия решений:
статистика востребованности компетенций, визуализации, а также
текстовые рекомендации.

---
[ОТЧЁТ Diamond.pdf#p=26] (folder=ОТЧЁТ Diamond, page=26)
Результат Фазы 4
Артефакт: Подтвержденные Проектные Задачи и завершенное Партнерское Со-
глашение

---
[ОТЧЁТ Diamond.pdf#p=15] (folder=ОТЧЁТ Diamond, page=15)
ЗАКЛЮЧЕНИЕ
Соответствие требованиям заказчика: по итогам семестра создан
работоспособный прототип, который автоматизирует ключевой сценарий Фазы
1 — извлечение и сопоставление компетенций между рынком труда и учебными
проектами, а также формирует аналитические артефакты (статистика,
визуализации, рекомендации). Это означает, что продукт уже поддерживает
принятие решений по корректировке программы и выбору фокуса анализа, а не
просто “выполняет отдельные задачи”. На данный момент проект не готов к
интеграции в “ПроКомпетенции”, так как интерфейс не подходит для
автономной агентной работы. Тем не менее, это соответсвует требованиям
заказчика, так как проект не рассчитан на один семестр.
Оценка качества по результатам тестирования: качество продукта
определяется двумя компонентами — корректностью данных и стабильностью
вывода LLM. Выявленные дефекты (ошибки извлечения компетенций,
нестабильный формат, нерелевантные элементы) имеют заметное влияние на
точность аналитики, поэтому ручная валидация и постобработка остаются
обязательными. Иногда встречаются явные галлюцинации из-за жесткого
квантования, что говорит о том, что требуется дообучение адаптеров.
Подключение QLoRA‑адаптера и уточнение промптов улучшают
повторяемость результатов, но полностью не устраняют необходимость
контроля качества на репрезентативных выборках.
Предложения по улучшению и развитию:
1) Ввести автоматическое тестирование;
2) Интегрировать сбор проектов в проект, а не отдельно от проекта в виде
расширения;
3) Использовать динамическое дообучение QLoRA;
4) Интеграция в ПроКомпетенции для тестирования на реальных
пользователях.

ПРАВИЛА:
- Отвечай строго по контексту. Никаких знаний "из головы".
- Если прямого ответа нет в контексте — напиши ровно: Не найдено в контексте.
- Запрещено придумывать цитаты/страницы/идентификаторы.
- Любое ключевое утверждение в ответе должно быть подтверждено 1–3 цитатами из контекста.

ФОРМАТ ОТВЕТА (строго, 2 строки):
Ответ: <1–3 коротких предложения или "Не найдено в контексте.">
Цитаты: <1–3 цитаты вида [....] из контекста, либо "—" если не найдено>

assistant
<think>
Okay, let's tackle this query. The user is asking about the tasks listed for the next KT (Knowledge Transfer) in both blocks. 

First, I need to look through the provided context to find mentions of tasks related to the next KT. The first document, [Diamond кт1.pdf#p=10], has a section titled "Задачи на следующюю кт" which lists two blocks: ФОРМИРОВАНИЕ ПУЛА И СКОРИНГ and СТРАТЕГИЧЕСКАЯ КОММУНИКАЦИЯ. Each block has three tasks.

The first block, ФОРМИРОВАНИЕ ПУЛА И СКОРИНГ, includes:
1. Поиск компаний в утвержденной отрасли
2. Скоринг и ранжирование компаний
3. Подготовка профилей компаний

The second block, СТРАТЕГИЧЕСКАЯ КОММУНИКАЦИЯ, includes:
1. Генерация персонализированных черновиков
2. Подготовка коммуникационных материалов
3. Планирование касаний

I need to make sure these are the only tasks mentioned in the context. The other documents talk about recommendations, QLoRA adapters, and project phases, but not about the tasks for the next KT. So the answer should list these tasks from the first document. The user wants the answer strictly based on the context, so I'll present the tasks as listed there.
</think>

Ответ: Задачи на следующую КТ включают формирование пула и скоринг, а также стратегическую коммуникацию.  
Цитаты: [Diamond кт1.pdf#p=10] (ФОРМИРОВАНИЕ ПУЛА И СКОРИНГ: 1) Поиск компаний... 3) Подготовка профилей компаний; СТРАТЕГИЧЕСКАЯ КОММУНИКАЦИЯ: 1) Генерация персонализированных черновиков... 3) Планирование касаний).

